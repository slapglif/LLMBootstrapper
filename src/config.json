{
    "tokenizer": "gpt2",
    "max_length": 512,
    "batch_size": 32,
    "num_workers": 4,
    "checkpoint_dir": "checkpoints",
    "early_stopping_patience": 3,
    "log_dir": "logs",
    "model_dir": "models",
    "max_epochs": 10,
    "gpus": 1,
    "use_mixed_precision": true,
    "accumulate_grad_batches": 1,
    "gradient_clip_val": 1.0,
    "val_check_interval": 0.25,
    "log_every_n_steps": 50,
    "learning_rate": 5e-5,
    "weight_decay": 0.01,
    "vocab_size": 50257,
    "d_model": 768,
    "n_heads": 12,
    "d_ff": 3072,
    "n_layers": 12,
    "dropout": 0.1,
    "use_mamba": true,
    "d_state": 16,
    "d_conv": 4,
    "expand_factor": 2.0,
    "dt_rank": 8,
    "dt_min": 0.001,
    "dt_max": 0.1,
    "sliding_window_size": 512
}